%\documentclass{article} %[twocolumn] 
%\documentclass[Crown, times, sagev]{sagej}
\documentclass[sagev, Crown]{sagej} %

%\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{array}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{url}

\setcounter{secnumdepth}{3} %Gives section numbers for cross referencing
\begin{document}

\runninghead{Wilson et al.}

\title{Estimating and maximising the expected utility of pilot trials using surrogate decision rules}

\author{Duncan T. Wilson\affilnum{1}}%,
%Rebecca E. A. Walwyn\affilnum{1}, 
%Julia Brown\affilnum{1} and 
%Amanda J. Farrin\affilnum{1}}

\affiliation{\affilnum{1}Leeds Institute of Clinical Trials Research, University of Leeds, Leeds, UK} %\\
%\affilnum{2}Centre for Primary Care \& Public Health, Queen Mary University of London, London, UK}

\corrauth{Duncan T. Wilson, Clinical Trials Research Unit, Leeds Institute of Clinical Trials Research, University of Leeds, Leeds, LS2 9JT, UK}
\email{d.t.wilson@leeds.ac.uk}

\begin{abstract}
% (250 limit for SiM)

\end{abstract}

\keywords{Clinical trial, pilot trial, external pilot, statistical decision theory, optimal design, expected value of sample information, Monte Carlo methods}

\maketitle

\section{Introduction}

- Large, definitive trials are typically designed according to frequentist OCs, which are conditional on unknown parameters
- Pilot trials are used to get parameter estimates, but are not always feasible, e.g. will never get a precise ICC estimate so will always be uncertain
- Bayesian design approaches have been proposed to allow for parameter uncertainty to be dealt with properly
- One specific Bayesian approach is to define a utility function and design to maximise expected utility
- When using this approach, we may still want to use a pilot to get information and revise our prior to a posterior; extends naturally to looking at efficacy as well as nuisance params
- There is a balance between the cost of the pilot and the value of the information it will produce
- The BSDT approach deals with this automatically, we design the pilot to maximise EVSI
- But, estimating and maximising EVSI is computationally challenging in all but a handful of scenarios
- Here, we discuss some existing approaches to EVSI and how they could be applied to the pilot design problem, propose a new approach, and compare their performance when applied to a number of illustrative examples

When there is substantial uncertainty regarding the parameters prior to the planned definitive trial, a small pilot trial can be run to obtain some relevant information. Many methods have been proposed to design these pilot trials and to guide how their data should be used to inform the definitive trial, when the goal is to estimate a nuisance parameter. In some situations, this approach has been shown to be inappropriate. For example, using a pilot to estimate an ICC, it has been shown that for the estimate to be sufficiently precise the pilot will need the same kind of sample size as the definitive.
\cite{Teare2014}
\cite{Julious2006}
\cite{Whitehead2015}
\cite{Eldridge2015}
\cite{Lake2002}
\cite{Grayling2018}
\cite{Proschan2005}
\cite{Schie2014}
\cite{Wittes1990}

Given the small sample size of pilot trials and the subsequent inability to make any firm conclusions or provide very precise parameter estimates under a frequentist model, a Bayesian approach to their design and analysis is attractive. Given appropriate prior distributions describing initial knowledge and uncertainty in any unknown parameters, the pilot data can be used to update these and provide posterior distributions, which can in turn be used to determine the optimal design of the definitive trial (including the decision of whether or not to run the trial at all) under a Bayesian statistical decision framework (which requires the specification of a utility function). The pilot trial itself can then be designed so as to maximise the expected utility of the pilot-definitive trial programme. This is also known as maximising the expected value of sample information.
\cite{Lindley1957}
\cite{Gittins2000}
\cite{Gittins2000a}
\cite{Gittins2002}
\cite{Halpern2001}
\cite{Willan2005}
\cite{Turner2004}
\cite{Spiegelhalter2001}

This approach would naturally cover all unknown parameters, including the treatment effect. This would be an improvement on current practice, where pilots are not generally used to estimate efficacy due to concerns about low power. 
\cite{Cocks2013}
\cite{Lee2012}
\cite{Sim2019}
\cite{Lancaster2004}
\cite{Arain2010}
\cite{Thabane2010}
\cite{Stallard2012}

A practical consideration when taking this approach is the computational challenge it presents. Other than in very special cases involving conjugate priors, simulation-based methods are generally required. A simple approach involves a two-level nested MC routine, where pilot data are simulated and for each data set, a set of posterior samples is generated using e.g. MCMC and this is then used to find the optimal terminal decision (in our case, the optimal definitive trial design). As this can take weeks to run, several researchers have developed fast approximations, generally based on using some kind of regression to approximate the expected utility, conditional on the pilot data sufficient statistics, of each decision. This approach may prove difficult if we have a large space of decisions (e.g. a large potential definitive trial sample size) or a continuous one (e.g. the alpha of the definitive trial). We could discretise the space, to get the speed but at the cost of accuracy.
\cite{Strong2014}
\cite{Strong2015}
\cite{Menzies2015}
\cite{Heath2017}
\cite{Jalal2017}
\cite{Heath2019}

We propose a different approach, where we recognise that an MEU analysis of pilot data will map the data to corresponding optimal definitive trial designs, i.e. it will provide a decision rule. Moreover, this decision rule is optimal in the sense that it will have the largest expected utility. We will show that because we can estimate the expected utility of any decision rule, we can solve the problem by considering surrogate rules and search over these, knowing that the optima will coincide with MEU. 

The remainder of this paper is structured as follows...

\section{Problem and motivating example}\label{sec:problem}

Consider settings where an external pilot is to be conducted in advance of a definitive trial. Denote the per-arm sample size of these trials by $n_1$ and $n_2$ respectively. The primary analysis of the definitive trial will be a conventional hypothesis test comparing the control and intervention arms, using a type I error rate of $\alpha_2$. Denoting the unknown parameters by $\theta$, we specify a prior distribution $p(\theta)$ before the pilot trial is conducted. The pilot data, denoted $x_1$, is then used to obtain the posterior $p(\theta ~|~ x_1, n_1)$. The sample size and type I error rate of the definitive trial will be chosen so as to maximise the expected value of a utility function with respect to this posterior distribution.

Given this procedure, the only decision to be made is the choice of pilot sample size $n_1$. We do this by maximising the expected utility of the full pilot-then-definitive trial programme, with respect to the prior $p(\theta)$. Aside from the operational issues of specifying an appropriate prior and utility function, the main methodological issue is calculating the expected utility of a programme with pilot sample size $n_1$. 

\subsection{Motivating example - REACH}

REACH was two-arm parallel group cluster randomised external pilot, where each cluster was a care home. REACH aimed to recruit $n_1 = 6$ care homes into each arm. The number of residents from each care home subsequently recited into the trial was random, but with some prior idea in terms of the average number and the variation in it between care homes. 

The definitive trial was to be designed to detect an effect of $\mu = 0.2$, using the standard design effect formula for cluster randomised trials with uncertain cluster sizes:
$$
n_2 = n [1 + (\bar{m} + cv^2 - 1)\rho].
$$
A more direct way to state the definitive trial sample size calculation notes that the intended analysis is a $z$-test of cluster means. We can therefore focus on the variance of cluster means as the nuisance parameter of interest, and use a standard sample size formula. That is, rather than decompose the variance into its various components, we can estimate it directly from the pilot data.

We specify the prior using the decomposition. Specifically, we put an inverse normal gamma joint prior on the mean and variance of the cluster sizes. We then use an inverse gamma prior for the within-cluster variance $\sigma_w^2$, and a beta prior for the intracluster correlation $\rho$. Together, these imply a prior for the nuisance parameter of interest, the cluster mean variance $\sigma^2_c$. This is not a conjugate prior for the corresponding sampling model (where the estimate follows a scaled chi-squared distribution), and so we would need to use some numerical sampler when analysing the pilot data and computing the posterior.

Given this prior on $\theta = (\mu, \sigma_c^2)$, we set up a utility function as in WP3.1.

\section{Methods}

We assume utility can be expressed as a function of the parameter values, sample sizes at each stage, data obtained at each stage, and type I error rate used in the definitive trial. The expected utility of the full programme with a given pilot sample size $n_1$ is then
\begin{equation}\label{eqn:MEU}
\mathbb{E}_{x_1 | n_1} \left( \max_{n_2} \mathbb{E}_{\theta | x_1, n_1}[u(\theta, n_1, x_1, n_2, x_2)] \right).
\end{equation}
We consider the most general case where the posterior distribution $p(\theta ~|~ x_a, n_1)$ is not known in closed form.

We consider three approaches to estimating the expected utility of equation (\ref{eqn:MEU}). Firstly, we describe a conceptually simple but computationally challenging nested Monte Carlo approach. We follow this by describing a new method which aims to improve efficiency by replacing a nested simulation with an optimisation problem. Finally, we describe a method proposed for estimating the Expected Value of Sample Information (EVSI) use health economic models.

\subsection{Two-level nested Monte Carlo}\label{sec:nested_MC}

For any given $n_1$, expected utility can be estimated using a two-level nested Monte Carlo routine as described in Algorithm \ref{alg:nested_MC}. 

\begin{algorithm}
\caption{Two-levl nested Monte Carlo}\label{alg:nested_MC}
\begin{algorithmic}[1]
\For{$1 = 1, 2, \ldots N$}
\State Sample $\theta^{(i)} \sim p(\theta)$
\State Sample pilot data $x^{(i)} \sim p(x ~|~ \theta^{(i)}, n_1)$
\State Draw $M$ samples from the posterior, $\theta^{(j)} \sim p(\theta ~|~ x^{(i)}, n_1)$
\State Find  $n_2^{(i)} = \arg\max_{n_2} \frac{1}{M} \sum_{j=1}^{M} u(\theta^{(j)}, n_1, x_1^{(i)}, n_2)$
\EndFor 
\State Calculate $\frac{1}{N} \sum_{i=1}^{N} \mathbb{E}_{x_2 | \theta^{(i)}, n_1, x_1^{(i)}, n_2^{(i)}}[ u(\theta^{(i)}, n_1, x_1^{(i)}, n_2^{(i)}) ]$
\end{algorithmic}
\end{algorithm}

The algorithm involves first sampling $N$ draws $\theta^{(i)}, i=1,\ldots,N$ from the prior distribution $p(\theta)$, and for each of these sampling a corresponding pilot data $x^{(i)} \sim p(x ~|~ \theta^{(i)}, n_1)$. Then, for each data set we use a numerical Bayesian sampler (e.g. Stan) to obtain a set of samples from the posterior distribution $p(\theta ~|~ x^{(i)}, n_1)$. We then use these to determine the optimal sample size of the definitive trial. Finally, we average over the $N$ samples in the outer loop to obtain a Monte Carlo estimate of the expected utility of the full programme.

Algorithm \ref{alg:nested_MC} will produce an unbiased estimate of the true expected utility, with a known standard error that will reduce at a rate of $1/\sqrt(N)$, under the assumption that the sampling and optimisation of steps 4 and 5 are sufficiently robust. It is computationally intensive because for each of the $N$ outer loop iterations we are required to run a numerical sampler and then solve an optimisation problem.

\subsection{Surrogate decision rules}

Algorithm \ref{alg:nested_MC} involves finding an optimal definitive trial sample size for a number of simulated pilot data sets (see steps 4 and 5), and then using these $n_2$'s to estimate expected utility. Here we consider an alternative approach where steps 4 and 5 are replaced by a pre-specified decision rule $d(x_1): \mathcal{X}_1 \rightarrow N$. Note that
$$
\max_{n_2} \mathbb{E}_{\theta | x_1, n_1}[ u(\theta, n_1, x_1, n_2, x_2)] \geq \mathbb{E}_{\theta | x_1, n_1}[ u(\theta, n_1, x_1, d(x_1), x_2)] 
$$
for all $d$. So, we can recast the problem as one of finding the optimal decision rule $d$, knowing that the global optima coincides with equation (\ref{eqn:MEU}). Having removed the inner maximisation, we can re-write the expected utility of a pilot trial with sample size $n_1$ and decision rule $d$ as
\begin{align}\label{eqn:surr}
\mathbb{E}_{x_1 | n_1} \left[ \mathbb{E}_{\theta | x_1, n_1}[ u(\theta, n_1, x_1, d(x_1), x_2)] \right]
& = \mathbb{E}_{x_1, \theta | n_1} \left[ \mathbb{E}_{x_2 | \theta, x_1, n_1} [ u(\theta, n_1, x_1, d(x_1), x_2)] \right]. \nonumber \\
\end{align}
The inner expectation depends only on the conditional distribution of the definitive trial data $x_2$, given the true parameters $\theta$. This utility will take one of two values, depending on whether or not the definitive trial data leads to a rejection of the null hypothesis. The probability of this event is the power of the definitive trial, denoted $1-\beta(\theta)$. Then,
\begin{align}
\mathbb{E}_{x_2 | \theta, x_1, n_1} [ u(\theta, n_1, x_1, d(x_1), x_2)] & = (1 - \beta(\theta)) u(\theta, n_1, d(x_1), x_2 > c_2) + \beta(\theta)u(\theta, n_1, d(x_1), x_2 \leq c_2),
\end{align}
which can be calculated exactly whenever the power function of the definitive trial is known. The outer expectation can be approximated by by a Monte Carlo estimate, giving
\begin{align}
\mathbb{E}_{x_1 | n_1} \left[ \mathbb{E}_{\theta | x_1, n_1}[ u(\theta, n_1, x_1, d(x_1), x_2)] \right] & \approx \frac{1}{N} \sum_{i=1}^{N} \mathbb{E}_{x_2 | \theta^{(i)}, n_1, x_1^{(i)}}[ u(\theta^{(i)}, n_1, x_1^{(i)}, d(x_1^{(i)}), x_2) ],
\end{align}
where $\theta^{(i)}, x^{(i)} \sim p(\theta, x)$. This avoids the computationally intensive nested Monte Carlo of algorithm \ref{alg:nested_MC}, at the expense of requiring equation (\ref{eqn:surr}) to be calculated repeatedly in the context of a search over a space of decision rules.

%Note - maximising the MC approximation would be achieved by taking each term in the summation and finding the n2 which is optimal for that theta. We could construct a generalised rule d from this by just defining the obvious piecewise constant function. But while this rule will maximise the approximation, it won't maximise the actual expectation - it is a case of massively overfitting the rule to the MC data. This doesn't happen in our spline formulation, but only by accident - the smoothness of the splines avoids this. Recall that when we allow for two many knots in the splines, we find optimal rules which are very wriggly.

%So, we need to be more precise in the above. Need to show that maximising the MC approximation is not actually what we want to do. And we need at least a way to identify overfitting - this could just be simulating another set of parameters and data, applying the rule, and then revisiting if there is a drop in expected utility (beyond the MC error). 

\subsubsection{Splines}

We consider decision rules defined over a space of cubic spline functions. Considering first the case where the pilot data can be summarised by a scalar sufficient statistic, we set the spline knots at even quantiles of the samples $x_1^{(1)}, \ldots , x_1^{(N)}$ (with the number of knots to be chosen). Given these pre-specified knots, we can obtain the the set of $k + 4$ cubic splines which serve as a basis for the space of all cubic splines defined over the same knots. Denoting these so-called b-splines by $\phi_i(x_1), k=1,\ldots,k+4$, a decision rule is then
$$
d(x_1) = \left\lfloor \sum_{i=1}^{k+4} a_i \phi_i(x_1) \right\rfloor,
$$
where we apply the floor operator $\left\lfloor . \right\rfloor$ to convert the continuous spline function into the required integer output. Searching over the space of decision rules then amounts to searching over the space of vectors $\mathbf{a} = (a_0, a_1, a_2, \ldots , a_{k+3})$, solving

\begin{align}\label{eqn:opt}
\max_{\mathbf{a_n}, \mathbf{a_{\alpha}}} ~ & \frac{1}{N} \sum_{i=1}^{N} \mathbb{E}_{x_2 | \theta^{(i)}, n_1, x_1^{(i)}}[ u(\theta^{(i)}, n_1, x_1^{(i)}, d(x_1^{(i)}), x_2) ] \\
\text{subject to} ~ & \mathbf{a_n} > 0, i=1,2. \nonumber
\end{align}


We can solve this problem using an appropriate optimisation algorithm, such as Subplex \cite{Rowan1990} as implemented in R via the package `nloptr' \cite{Ypma2018}.

For sufficient statistics of dimension $\geq 2$, we can apply the same approach using tensor product splines. For example, we can deal with the two statistics $x_1$ and $y_1$ by first constructing the b-splines for each one dimensional space, $\phi_i(x_1), k=1,\ldots,k+4$ and $\psi_i(x_1), k=1,\ldots,k+4$ respectively, and then using decision rules of the form 
$$
d(x_1, y_1) = \left\lfloor \sum_{i=1}^{k+4} \sum_{j=1}^{k+4} a_{i,j} \phi_i(x_1) \psi_j(y_1) \right\rfloor.
$$
Although this approach can be extended in theory to any number of dimensions, in practice we find we are limited to two or three at most due to the explosion in number of coefficients, and therefore in the dimensions of the optimisation problem's solution space, resulting from the nested summations. For example, using b-splines defined over $k = 6$ knots in three dimensions requires $(k+4)^2 = 1000$ coefficients. When solving problems in two dimensions, we use the large-scale optimisation algorithms implemented in the R package `BB' \cite{Varadhan2009}.

\subsubsection{Example}

May want to include a high-level example here, showing an optimal decision rule and how it can be composed of spline basis functions, thus defining the solution to the optimisation problem.

\subsection{Nonparametric regression}

An alternative approach has been suggested in the context of calculating the expected value of information for a definitive trial \cite{Strong2015}. To apply this to our problem, we first create a set of potential definitive trial designs (i.e. $n_2, \alpha_2$ pairs). As in the previous two methods, we simulate $N$ samples from $p(\theta, x_1)$. For each design, the expected utility conditional on the pilot data $x_1$ is then estimated by calculating the utility of the design for each $\theta$ and regressing on the corresponding $x_1$. Given this set of regression models, we then proceed to estimate the conditional expected utility for each $k$ for each $x^{(i)}$ and choose the $k$ with the largest of these. Thus, we have mapped our samples $x^{(i)}$ to decisions, and can estimate expected utility as before. 

%Would involve taking the simulated outer loop samples and using these to build a regression model for each definitive trial sample size, predicting expected utility of that sample size from the pilot data. Then for each x we choose the n with largest expected utility at that point. Harder to generalise to another design param - exponential growth of regression models. Even just for sample size, this can take some time - fitting one model to $10^5$ samples and then predicting utility at these takes 9.8 seconds; and we might want to fit 100 of these. And the standard errors of the GAM method are larger, meaning we would need to increase the outer sample by around 1.44 - 2.6 times to get the same precision (from the Strong paper). And this all then needs to be done several times to get an optimal pilot sample size. So in total we would be looking at around 4 hours (compared with the 172s of the proposed method in example 1, 80 times faster). Would scale very poorly if we add another design variable, e.g. alpha - would need a grid of regression models, so increasing run time by a factor of 10 - 100 say.

\subsection{Standard errors}

Need to quantify the uncertainty in our estimates of EVSI. 

For two-level MC, this is easy enough. And should be able to get it for the regression approach from their appendix.

For our method, we have two sources of error. First, conditioning on the rule(s), we have MC error in the outer loop. Second, there is error in determining the rule itself, random on the part of the outer samples, and systematic on the part of the algorithm. So, probably not feasible to get an analytical expression - would be forced to bootstrap, which would take too long. So, focus instead on checking that the rule is correct, and then conditioning everything on that. 

\section{Illustrative applications}

For all examples we will use the same basic utility set-up. Following WP3.1, we use an exponential utility (with risk parameter $\rho$) based on an additive value function with three attributes: the total sample size, the change in average primary endpoint, and the cost of treatment.

For each example we will compare with the nested method, which we may be able to shortcut in some way. We want to compare performance for different outer samples $N$. For the surrogate method, we may want to see how performance changes if we use $N=10^6$ for the final expectation, but use only a subset for the building of the rule. Equivalently, ask whether we can get the extra precision of a high $N$ but without the bias of a low rule-building $N$.

For all examples, compare methods in terms of estimating the utility of a programme for a fixed $n_1$. After this, show how we can also optimise $n_1$ when using the surrogate approach. Don't need to implement the bisection search using the nested MC or GAM approach - can just give an indication of runtime based on complexity bounds for a simple bisection search.

\subsection{Normal endpoint with known variance (OK-Diabetes)}

To make the ideas clear, apply the new method to a simple hypothetical example which we can solve (almost) exactly using method 1 - a normal prior on treatment effect, known variance. 

Use the three methods to optimise $n_1$. Use a bisection search for the last two methods. Report the suggested sample size with the associated estimated utility and the standard error in it. For the optimal $n_1$, illustrate the method more fully by showing the decision rules given by each method, and showing how the spline function is formed. 

Do this for $10^4, 10^5$ and $10^6$ samples.

\subsection{Normal endpoint with clustering (REACH)}

Setting: a cRCT with fixed $m$ but unknown total variance and unknown ICC; priors on these as following Speigelhalter 2000, giving a non-conjugate prior on the variance of cluster means; normal prior on treatment effect. For the definitive trial sample sizing we are interested only in the cluster mean variance and effect size, so a 2D summary statistic.

Break this down into two examples. First, we consider learning only about the cluster mean variance. This corresponds to assuming the effect at stages 1 and 2 are independent, which we can think of as an extreme version of the `pilots are biased' argument. In this case we have a 1D summary stat.

Next, look at the 2D problem where we measure and learn both the variance and the effect size.

For both sub-problems, we will need to use the full nested MC approach as the comparison, which will take days/weeks to run.

\section{Results}

\section{Extensions}

\subsection{Optimising $n_1$}

Since our method is quite fast and the pilot sample size will generally be small, the simplest thing to suggest here is a repeated application for a number of candidate choices, followed by further iterations as required. We can apply this approach using all methods and plot here. 

We can then note that the proposed method can potentially be sped up by incorporating $n_1$ directly into the optimisation problem. Thus, we now search over the joint space of decision rules and pilot sample size to find that with maximum expected utility. The addition of an extra solution variable does not have a large impact on the difficulty of solving the problem; and we would expect it to lead to efficiencies over the alternative by allowing information regarding the form of decision rule to be shared, in the sense that we would expect similar optimal decision rules for similar $n_1$s.

In practice, we execute this approach by first simulating a sequence of pilot data sufficient statistics for each sampled parameter $\theta^{(i)}$, giving a set of samples $\mathbf{x}^{(m)}, m = 0, 1, \ldots , n_1^{max}$. For each $\mathbf{x}^{(m)}$ we must set up the b-spline basis functions. When optimising we treat $n_1$ as a continuous variable, and estimate the expected utility for any non-integer $n_1$ as the linear combination of the expected utility of its floor and ceiling. 

A potential difficulty is in getting the derivative of the objective with respect to $n_1$. Could always fall back on a numerical method for this part of the vector, if that doesn't slow things down too much.

\subsection{Other types of endpoints}

Briefly note that we can use this approach for binary endpoints - use CLT to get an equivalent power function, and use the absolute difference in proportions as the effect in the utility function. What about survival? There, the pilot will estimate the effect (i.e. hazard ratio) and the nuisance parameter, the event rate in the control arm. Like binary, we can appeal to the CLT and use the method without much modification. Would need to expand to choosing three design variables - alpha, sample size, and follow-up time - and incorporate time into the utility.

Anything that we suggest here, provide a full worked example for in the SM.

\subsection{Constrained $\alpha$}

It is a trivial reduction of the method to keep $\alpha$ fixed and search for sample size decision rules only. If we wanted to instead cap at $\alpha^*$, we can just change from using b-splines to m-splines, inverted and offset by $\Phi^{-1}(\alpha^*)$.

\subsection{Internal pilots}

In an internal pilot we use the pilot data in the final analysis. If we are searching over $\alpha$, the method can be applied directly. We may want to estimate the actual $\alpha$ once the optimal design has been found, but this wouldn't be strictly necessary.

If we want to constrain $\alpha$, this is a bit trickier. We won't be able to get this in closed form, but could calculate numerically - we will have the alpha for each sample value from the decision rule, so just need to average these w.r.t. the sample distribution - could often use numerical integration for this, or MC in the general case. Ideally, we would like to incorporate this into the optimisation problem as a constraint.
%See if we can implement this in the SM, otherwise move to discussion



% FOR DISCUSSION
We can go beyond a single interim analysis. Suppose we have k interim analyses, at each stage deciding the sample size of the next stage. At the final stage, the chosen sample size will be recruited and the full sample will be used in a frequentist test, and we can control the actual type I error as above. Thus, we need to find k decision rules rather than just one. 

What about a more flexible sequential design? The standard approach finds efficacy and futility bounds at each sampling stage. We could do standard forward sampling here to find these bounds, for given stages. But, we could allow not just stopping, but choice of next stage sample size. This would need some kind of ineterim analysis penalty. Could link this to time - doing an interim will stop recruitment for the length of the endpoint. Would then need to tradeoff effect obtained by time we obtain it, so for our utility we would need linear value in time and preference independence - seems reasonable. And this would correspond with a fixed additive penalty for each analysis. In the simplest case of known variance, we would then want to find a smooth surface over sample mean and sample size giving the next stage sample size, together with two functions representing efficacy and futility stopping boundaries (mapping sample size to sample mean in each case).



\section{Discussion}


In \cite{Brunier1994} they consider a similar problem but with a single arm pilot and a fixed phase III sample size (so the decision is just stop/go), with binary endpoint. Same with \cite{Stallard1998}.

To apply this method, we need an analytic form for the expected utility with respect to the main trial data but conditional on the model parameters. This boils down to needing a power function.

We also need differentiability for the method to work well. So, beyond just a power function, we need a differentiable one. Note that this is satisfied whenever we use the CLT, which will often be the case for definitive trials. We then also need the utility function to be differentiable in $n$. 

Other kinds of surrogate rules. In particular, note that we don't actually want to maximise the MC approximation given - we could do this by defning the piecewise constant function which maximisises each individual term, but we would not expect this to fit well to another set of simulated data. So, we see that by using splines, we are ensuring the functions are smooth.

Our method involves, at each iteration, calculating the utility of a definitive trial from a set of $\theta, n_2$ pairs. The $\theta$s are the same each time, but the $n_2$'s vary. For us, this is not a problem as the utility calculation is simple; but for complex health economic models it may be computationally demanding. The HE literature often talks about generating one PSA sample and not requiring any more - our method has this property, but may limit it since here we have a large set of decisions, not just 2 or three. Perhaps a key distinction between this and the HE context - utilities generally quite simple? But need to show that in this simple setting, the HE methods are not (uniformly) better than the proposal. Note that \cite{Heath2017} notes that \cite{Strong2015} will tend to be better for low dimensional summary stats, so we can assume this is the competitor for our problem. This is further backed up in the case study comparisons in \cite{Heath2020}. And the NP regression method has exactly the same difficulty - need to calculate the utilities for each of the decisions. Can do this all at the start, off-line.

Forward sampling - if we had a sequential analysis with a fixed sample size at each stage, the decisons are futile/continue/effective and our approach would reduce to the forward sampling method in \cite{Carlin1998}. Note though that they search over decision boundaries for each stage, whereas our approach would define continuous stopping boundaries rather than discrete. This might be more helpful if the stage sample size is variable? Also note that the problems could well coincide exactly if we define the splines to be piecewise constant, i.e. of degree 0 rather than 3. A potential difficulty in extending to this setting is differentiability of the objective.

\begin{acks}
Acknowledgements.
\end{acks}

\begin{dci}
The Authors declare that there is no conflict of interest.
\end{dci}

\begin{funding}
This work was supported by the Medical Research Council [grant number MR/N015444/1].
\end{funding}

\bibliographystyle{SageV}
\bibliography{C:/Users/meddwilb/Documents/Literature/Databases/DTWrefs}

\section*{Appendix}

\subsection*{Derivatives}

Take each element of the sum as a function of coefficient $a$, with fixed $x_1 = x_1^{(i)}$. Then,
\begin{align*}
f(a) 	&= g(a)u_1(a) + (1 - g(a))u_2(a) \\
f'(a) 	&= g'(a)u_1(a) + g(a)u_1'(a) + u_2'(a) - g'(a)u_2(a) + g(a)u_2'(a) \\
		&= g'(a)(u_1(a) - u_2(a)) + g(a)(u_1'(a) - u_2'(a)) + u_2'(a)\\
		&= g'(n(a))n'(a)(u_1(a) - u_2(a)) + g(a)(u_1'(n(a))n'(a) - u_2'(n(a))n'(a)) + u_2'(n(a))n'(a)\\
		&= n'(a) [ g'(n(a))(u_1(a) - u_2(a)) + g(a)(u_1'(n(a)) - u_2'(n(a))) + u_2'(n(a)) ]
\end{align*}

In our case,
\begin{align*}
g(a) 		&= 1 - \Phi \left(z - \frac{\mu}{\sqrt{2\sigma^2/n}} \right)\\
g'(n(a)) 	&= - \phi \left(z - \frac{\mu}{\sqrt{2\sigma^2/n}} \right)\frac{-\mu}{2\sqrt{2n\sigma^2}},
\end{align*}

\begin{align*}
u_1(a)		&= 1 - e^{-\rho(k_d\mu + k_n(n_p + n)} \\
u_1'(n(a)) 	&= \rho k_n e^{\rho(k_d\mu + k_n(n_p + n)},
\end{align*}

\begin{align*}
u_2(a)		&= 1 - e^{-\rho(k_n(n_p + n) + k_c} \\
u_2'(n(a)) 	&= \rho k_n e^{\rho(k_n(n_p + n) + k_c},
\end{align*}
and
\begin{align*}
n(a_j) 	&= \sum_{i=1}^{k+4} a_i \phi_i(x_1) \\
n'(a_j)	&= \phi_j(x_1)
\end{align*}
(drop $x_1$ to leave just $\phi_j$?)

With respect to coefficient $b$, defining the decision rule for $z$, we have
\begin{align*}
g'(a)		&= z'(a) [ g'(z(a))(u_1(a) - u_2(a)) + g(a)(u_1'(z(a)) - u_2'(z(a))) + u_2'(z(a)) ] \\
g'(z(a)) 	&= -\phi(z(a) - \frac{\mu}{\sqrt{2\sigma^2/n}},
\end{align*}

\begin{equation*}
u_1'(z(a)) 	= u_2'(z(a)) = 0,
\end{equation*}

and
\begin{align*}
z(a_j) 		&= \sum_{i=k+5}^{2(k+4)} a_j\phi_j(x_1) \\
z'(a_j)) 	&= \phi_j(x_1)
\end{align*}

So the vector the partial derivative is
\begin{align*}
h'(a_j) &= ... for j \leq k+4 \\
		&= ... for j \geq k+5
\end{align*}

\end{document}